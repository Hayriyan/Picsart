# 15-Month ML/DL Program ‚Äî Lab Plan

## Lab Plan Overview

**Structure:** 3 phases matching main curriculum  
**Format:** Deep practical work, large projects, self-education  
**Grading System:** Points-based (–±–∞–ª–ª—ã) ‚Äî students must accumulate minimum points to pass each phase  
**Philosophy:** Hands-on mastery through implementation, experimentation, and independent learning

### Lab Plan Principles

- **Depth Over Breadth:** Labs go deeper than lectures, requiring full implementation
- **Project-Based Learning:** Emphasis on large, integrated projects
- **Self-Education:** Students learn independently using provided materials
- **Progressive Complexity:** Start simple, build to advanced systems
- **Real-World Focus:** Projects use real datasets and solve actual problems
- **Points-Based Progression:** Students earn points from completed labs/projects to advance to next phase

---



## Teaching Team & Roles

### Lecture Role

**Primary Responsibilities:**

- **High-Level Curriculum Oversight:**
  - Approve overall lab structure and learning objectives
  - Review and approve lab progression paths and prerequisites
  - Establish high-level evaluation criteria and grading rubrics
  - Ensure alignment between lab content and theoretical lectures

- **Strategic Guidance:**
  - Provide high-level conceptual guidance on complex topics when needed
  - Review and approve major curriculum changes
  - Oversee final capstone project approvals (Phase 3)
  - Make final decisions on exceptional cases (phase advancement appeals, special accommodations)

- **Final Assessment Authority:**
  - Review final lab submissions for capstone projects (Lab 1.9, 2.10, 3.10)
  - Conduct final technical interviews for phase progression (when Practice Assistant requests review)
  - Approve phase advancement decisions
  - Handle grade appeals and exceptional cases

**Interaction Model:**
- Monthly check-ins with Practice Assistant
- On-demand consultation for complex theoretical questions
- Final capstone project reviews
- Phase transition final approvals (as needed)

---

### Practice Assistant Role

**Primary Responsibilities:**

- **Teaching & Lecturing:**
  - **Deliver lectures and lessons when needed** - Can substitute for Lecture or provide supplementary lectures
  - Teach theoretical foundations connecting lectures to labs
  - Conduct introductory sessions for each lab phase
  - Explain complex theoretical concepts in practical context
  - Provide conceptual guidance on all topics covered in labs
  - Deliver specialized lectures on tools, frameworks, and best practices

- **Curriculum Development & Content Creation:**
  - Develop and curate self-study materials (reading lists, papers, tutorials)
  - Create detailed lab task specifications and requirements
  - Develop reference implementations and code examples
  - Prepare assessment materials and evaluation frameworks
  - Create supplementary learning resources (video tutorials, code walkthroughs)
  - Design and update lab exercises and projects

- **Hands-On Lab Support:**
  - Provide real-time assistance during lab sessions
  - Help students debug code and troubleshoot implementation issues
  - Guide students through technical challenges
  - Demonstrate practical coding techniques and best practices
  - Conduct one-on-one tutoring sessions for struggling students

- **Code Review & Assessment:**
  - Review all student code submissions for quality and correctness
  - Provide comprehensive feedback on implementation approaches
  - Evaluate lab deliverables and assign preliminary grades
  - Conduct technical interviews for phase progression
  - Assess student understanding through code reviews and technical discussions
  - Make recommendations for phase advancement (final approval by Lecture for capstones)
  - Maintain detailed assessment records and progress reports

- **Technical Mentoring:**
  - Answer questions about tools, libraries, and frameworks
  - Help students navigate development environments
  - Assist with Git workflows and version control
  - Guide students through debugging and profiling
  - Provide career and academic guidance
  - Mentor students on research-level projects (all phases, including capstones)
  - Support students in choosing specialization paths

- **Progress Monitoring & Student Management:**
  - Track student progress through all lab assignments
  - Identify students who need additional support and create intervention plans
  - Monitor completion of deliverables and enforce deadlines
  - Maintain comprehensive records of lab participation and engagement
  - Generate progress reports for students and Lecture
  - Manage student groups and facilitate peer collaboration

- **Workshop & Training Facilitation:**
  - Conduct comprehensive workshops on specific topics (e.g., Git, testing, debugging, ML frameworks)
  - Organize peer code review sessions
  - Facilitate group discussions and problem-solving sessions
  - Lead hands-on demonstrations of tools and techniques
  - Conduct training sessions on new technologies and methodologies
  - Organize hackathons and coding challenges

- **Resource Support & Material Development:**
  - Help students locate and use self-study materials
  - Create and provide additional examples and code snippets
  - Share tips and tricks for efficient development
  - Connect students with relevant online resources
  - Develop and maintain a knowledge base of common issues and solutions
  - Create video tutorials and documentation

- **Lab Session Management:**
  - Plan and schedule lab sessions
  - Coordinate with Lecture on curriculum alignment
  - Manage lab resources and infrastructure
  - Ensure lab environment is properly configured
  - Handle technical issues during lab sessions

**Interaction Model:**
- Regular lab sessions (2-3 times per week) - primary teaching responsibility
- Drop-in office hours for questions (extended hours)
- Code review sessions (individual and group)
- Real-time support via chat/discussion platforms
- Weekly progress check-ins with all students
- Lecture delivery when needed (substitute or supplementary)
- Monthly reports to Lecture on student progress and curriculum needs

**Skills & Qualifications:**
- Strong programming skills in Python
- Experience with software engineering practices
- Deep familiarity with ML/DL concepts (for Phase 2-3 labs)
- Excellent communication and teaching abilities
- Ability to explain complex theoretical concepts clearly
- Experience in curriculum development and content creation
- Assessment and evaluation skills
- Patience and ability to adapt teaching methods to different learning styles
- Strong organizational and time management skills

---

### Role Collaboration

**Lecture ‚Üî Practice Assistant Coordination:**

- **Monthly Sync Meetings:** Practice Assistant reports student progress, curriculum needs, and any issues requiring Lecture's attention
- **Content Alignment:** Practice Assistant develops and maintains lab content; Lecture provides high-level approval and strategic guidance
- **Feedback Loop:** Practice Assistant identifies curriculum improvements and implements changes; Lecture reviews major changes
- **Assessment Collaboration:** Practice Assistant conducts all assessments and makes phase progression recommendations; Lecture reviews capstone projects and approves final phase transitions
- **Teaching Support:** Practice Assistant can deliver lectures when Lecture is unavailable or when supplementary teaching is needed
- **Resource Sharing:** Practice Assistant creates most materials; Lecture provides high-level resources and strategic input

**Student Support Model:**

1. **Self-Study Phase:** Students work independently using materials provided by Practice Assistant
2. **Teaching Phase:** Practice Assistant delivers lectures and lessons as needed, explaining theoretical foundations
3. **Implementation Phase:** Practice Assistant provides comprehensive hands-on support, debugging help, and technical guidance
4. **Review Phase:** Practice Assistant conducts all code reviews and preliminary assessments
5. **Assessment Phase:** Practice Assistant evaluates submissions and makes phase progression recommendations; Lecture reviews capstone projects and approves final decisions

---

## Phase 1: Computational & Programming Foundations Lab

**Focus:** CS fundamentals, Python mastery, algorithms, systems programming  
**Minimum Points Required:** 100 points to pass Phase 1

### Foundations & Algorithms

#### Lab 1.1: Python Fundamentals Deep Dive ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Provided Python tutorials, CS106A/B materials

**Tasks:**

1. **Data Structures Implementation**

   - Implement from scratch: Stack, Queue, Linked List, Binary Tree, Hash Table
   - Compare performance with built-in Python types
   - Write unit tests for all implementations
   - **Deliverable:** GitHub repo with implementations + performance analysis report

2. **Algorithm Implementation**
   - Sorting algorithms: Bubble, Merge, Quick, Heap Sort
   - Search algorithms: Binary Search, BFS, DFS
   - Graph algorithms: Dijkstra's, Topological Sort
   - **Deliverable:** Jupyter notebook with implementations, complexity analysis, visualizations

**Self-Education Component:**

- Study provided materials on algorithm complexity
- Read "Python Tricks" chapters (provided)
- Complete online algorithm visualization exercises

**Required Knowledge for This Lab:**

- Basic Python syntax and data types
- Understanding of fundamental data structures (arrays, lists)
- Basic algorithmic thinking
- Understanding of time/space complexity concepts
- Familiarity with Python testing (unittest or pytest basics)
- Git basics for version control

---

#### Lab 1.2: System Programming & Performance ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** OS concepts, Python internals documentation

**Tasks:**

1. **Memory Management Project**

   - Build memory profiler tool
   - Analyze memory usage of different data structures
   - Implement memory-efficient data processing pipeline
   - **Deliverable:** Memory profiling tool + analysis report

2. **Concurrency & Parallelism**
   - Implement parallel data processing system
   - Compare threading vs multiprocessing for different workloads
   - Build task queue system
   - **Deliverable:** Parallel processing framework + benchmark results

**Self-Education Component:**

- Study Python GIL documentation
- Read "High Performance Python" chapters (provided)
- Explore asyncio and concurrent.futures

**Required Knowledge for This Lab:**

- Python fundamentals (from Lab 1.1)
- Understanding of processes and threads concepts
- Basic understanding of memory management
- Familiarity with Python profiling tools
- Understanding of CPU vs I/O bound operations
- Basic system monitoring concepts

---

#### Lab 1.3: Data Structures & Algorithms Project ‚≠ê **MANDATORY**

**Points:** 18 points  
**Self-Study Materials:** CLRS algorithms book chapters, LeetCode patterns

**Large Project:**
**Build a Complete Data Processing System**

**Requirements:**

- Design and implement a system that processes large CSV/JSON datasets
- Use custom data structures for efficient storage
- Implement multiple algorithms for data analysis
- Include caching, indexing, and query optimization
- Handle edge cases and errors gracefully
- **Deliverable:**
  - Complete system with documentation
  - Performance benchmarks
  - Design document explaining choices
  - Presentation (10 minutes)

**Self-Education Component:**

- Study system design patterns
- Review database indexing concepts
- Practice algorithm optimization techniques

**Required Knowledge for This Lab:**

- All data structures from Lab 1.1
- All algorithms from Lab 1.1
- Understanding of algorithm complexity analysis
- File I/O in Python
- JSON/CSV parsing
- Basic understanding of data processing pipelines
- System design thinking

---

### Advanced Python & OOP

#### Lab 1.4: Object-Oriented Design Project ‚≠ê **MANDATORY**

**Points:** 15 points  
**Self-Study Materials:** Design patterns book, SOLID principles

**Tasks:**

1. **Design Pattern Implementation**

   - Implement 5+ design patterns (Factory, Observer, Strategy, Decorator, etc.)
   - Apply patterns to solve real problems
   - **Deliverable:** Pattern library with examples

2. **ML System Design**
   - Design and implement ML framework components:
     - Dataset class with iterator pattern
     - Model base class with strategy pattern
     - Trainer class with observer pattern
   - **Deliverable:** Mini ML framework (foundation for future labs)

**Self-Education Component:**

- Study "Design Patterns: Elements of Reusable OOP"
- Review ML framework architectures (scikit-learn, PyTorch)

**Required Knowledge for This Lab:**

- Python OOP fundamentals (classes, inheritance, polymorphism)
- Understanding of design principles (SOLID basics)
- Familiarity with common design patterns
- Understanding of composition vs inheritance
- Basic understanding of ML concepts (for ML system design part)

---

#### Lab 1.5: Software Engineering Practices ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Clean Code principles, testing best practices

**Tasks:**

1. **Testing & CI/CD**

   - Write comprehensive test suite (unit, integration, property-based tests)
   - Set up CI/CD pipeline (GitHub Actions)
   - Implement code coverage reporting
   - **Deliverable:** Test suite + CI/CD configuration

2. **Code Quality & Documentation**
   - Refactor existing codebase following clean code principles
   - Generate API documentation (Sphinx)
   - Set up linting and formatting (black, pylint, mypy)
   - **Deliverable:** Refactored codebase + documentation site

**Self-Education Component:**

- Study "Clean Code" principles
- Review open-source project structures
- Learn documentation tools

**Required Knowledge for This Lab:**

- Python package structure understanding
- OOP design from Lab 1.4
- Basic testing concepts
- Git and GitHub workflow
- Understanding of code quality principles
- Basic command-line usage

---

### Data Processing & Analysis

#### Lab 1.6: Data Pipeline Project ‚≠ê **MANDATORY**

**Points:** 20 points  
**Self-Study Materials:** ETL best practices, data engineering patterns

**Large Project:**
**Build End-to-End Data Processing Pipeline**

**Requirements:**

- Extract data from multiple sources (APIs, databases, files)
- Transform and clean data (handle missing values, outliers, encoding)
- Load into structured format
- Implement data validation and quality checks
- Create monitoring and logging system
- **Deliverable:**
  - Complete pipeline with error handling
  - Data quality report
  - Monitoring dashboard
  - Documentation and deployment guide

**Self-Education Component:**

- Study data engineering patterns
- Review Apache Airflow concepts
- Learn data validation techniques

**Required Knowledge for This Lab:**

- File I/O and data processing (from Lab 1.3)
- Error handling and logging
- Database basics (SQL queries)
- API interaction (HTTP requests)
- Data cleaning concepts
- Understanding of ETL processes
- Software engineering practices (from Lab 1.5)

---

#### Lab 1.7: Database & API Integration ‚≠ê **MANDATORY**

**Points:** 15 points  
**Self-Study Materials:** SQL advanced topics, REST API design

**Tasks:**

1. **Database Design & Optimization**

   - Design normalized database schema
   - Implement complex queries with joins and aggregations
   - Optimize queries with indexes
   - **Deliverable:** Database schema + query optimization report

2. **API Development**
   - Build REST API with FastAPI/Flask
   - Implement authentication and authorization
   - Create API documentation (OpenAPI/Swagger)
   - **Deliverable:** Complete API with documentation

**Self-Education Component:**

- Study database normalization
- Review API design best practices
- Learn authentication mechanisms

**Required Knowledge for This Lab:**

- SQL fundamentals (SELECT, INSERT, UPDATE, DELETE)
- Understanding of database relationships
- REST API concepts
- HTTP methods (GET, POST, PUT, DELETE)
- JSON data handling
- Python web framework basics (Flask or FastAPI)
- Authentication concepts

---

### Advanced Topics & Integration

#### Lab 1.8: Performance Optimization Project ‚≠ê **MANDATORY**

**Points:** 18 points  
**Self-Study Materials:** Performance optimization techniques, profiling tools

**Large Project:**
**Optimize Large-Scale Data Processing System**

**Requirements:**

- Take existing data processing system
- Profile and identify bottlenecks
- Optimize using:
  - Vectorization (NumPy)
  - Caching strategies
  - Parallel processing
  - Memory optimization
- Achieve 5x+ performance improvement
- **Deliverable:**
  - Optimized system
  - Performance analysis report
  - Before/after benchmarks
  - Optimization techniques documentation

**Self-Education Component:**

- Study NumPy internals
- Learn profiling tools (cProfile, line_profiler, memory_profiler)
- Review optimization case studies

**Required Knowledge for This Lab:**

- NumPy basics (arrays, operations, broadcasting)
- Understanding of performance bottlenecks
- Profiling concepts
- Memory management understanding
- Parallel processing concepts (from Lab 1.2)
- Data structures and algorithms (from Lab 1.3)
- System programming knowledge

---

#### Lab 1.9: Final Integration Project ‚≠ê **MANDATORY**

**Points:** 25 points  
**Self-Study Materials:** System architecture patterns, best practices

**Capstone Project:**
**Build Complete Data Science Platform**

**Requirements:**

- Integrate all Phase 1 concepts:
  - Data ingestion (APIs, databases, files)
  - Data processing and cleaning
  - Data storage and retrieval
  - API for data access
  - Monitoring and logging
  - Testing and documentation
- Use proper software engineering practices
- Handle production-level concerns (scalability, reliability)
- **Deliverable:**
  - Complete platform
  - Architecture documentation
  - Deployment guide
  - Demo video
  - Final presentation (20 minutes)

**Self-Education Component:**

- Study microservices architecture
- Review production deployment strategies
- Learn monitoring and observability

**Required Knowledge for This Lab:**

- All Phase 1 concepts integrated:
  - Python programming mastery
  - OOP and design patterns
  - Data processing and pipelines
  - Database and API integration
  - Software engineering practices
  - Performance optimization
- System design thinking
- Understanding of production concerns (scalability, reliability)
- Integration of multiple systems

---

#### Lab 1.10: Optional Advanced Topics üîµ **OPTIONAL**

**Points:** 8 points per topic (max 24 points)  
**Note:** Optional labs provide bonus points beyond the 100-point requirement

**Topics (Choose 2-3):**

- **Cython/Numba:** Write high-performance Python extensions
- **Distributed Systems:** Build distributed data processing with Dask
- **Web Scraping:** Advanced scraping with Scrapy, handling JavaScript
- **Graph Databases:** Work with Neo4j or similar
- **Message Queues:** Implement pub/sub system with RabbitMQ/Kafka

**Deliverable:** Project demonstrating chosen topics

**Required Knowledge for This Lab:**

- Basic Linux command-line usage
- Understanding of chosen topic area
- Python programming (for most topics)
- System concepts relevant to chosen topic

---

#### Lab 1.11: Advanced Linux & System Administration üîµ **OPTIONAL**

**Points:** 15 points  
**Note:** Optional lab providing bonus points beyond the 100-point requirement

**Self-Study Materials:** Advanced Linux administration guides, system internals documentation

**Tasks:**

1. **Advanced Shell Scripting & Automation**

   - Write complex bash scripts with error handling
   - Implement system monitoring scripts
   - Create automated backup and maintenance scripts
   - Use advanced text processing (awk, sed, regex)
   - **Deliverable:** Collection of production-ready shell scripts

2. **System Administration & Configuration**

   - Configure and manage system services (systemd)
   - Set up user management and permissions (ACLs, sudo)
   - Configure networking (iptables, firewall rules)
   - Manage system resources (cgroups, limits)
   - **Deliverable:** System configuration documentation and scripts

3. **Linux Performance Tuning**

   - Profile system performance (top, htop, iostat, vmstat)
   - Optimize kernel parameters
   - Tune I/O performance
   - Optimize memory usage
   - **Deliverable:** Performance tuning report with benchmarks

4. **Advanced File Systems & Storage**

   - Work with different file systems (ext4, XFS, Btrfs)
   - Set up and manage LVM (Logical Volume Management)
   - Configure RAID arrays
   - Implement disk encryption
   - **Deliverable:** Storage configuration and management guide

5. **Process Management & Debugging**
   - Advanced process management (signals, job control)
   - System debugging with strace, ltrace, gdb
   - Memory debugging and profiling
   - Kernel module basics
   - **Deliverable:** Debugging toolkit and documentation

**Self-Education Component:**

- Study Linux system internals
- Review advanced shell scripting techniques
- Learn system administration best practices
- Explore Linux performance optimization
- Study kernel architecture basics

**Deliverable:** Complete system administration project demonstrating advanced Linux skills

**Required Knowledge for This Lab:**

- Linux command-line proficiency
- Understanding of file systems and permissions
- Process management basics
- Shell scripting fundamentals
- System administration concepts
- Understanding of system services
- Network configuration basics

---

## Phase 2: Machine Learning Deep Dive Lab

**Focus:** ML algorithms from scratch, advanced ML topics, generative models  
**Minimum Points Required:** 100 points to pass Phase 2

### ML Foundations & Regression

#### Lab 2.1: Linear Models from Scratch ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Statistical learning theory, optimization textbooks

**Tasks:**

1. **Linear Regression Implementation**

   - Implement from scratch: OLS, Ridge, Lasso, Elastic Net
   - Derive and implement normal equation
   - Implement gradient descent variants
   - Compare with scikit-learn
   - **Deliverable:** Complete implementation + mathematical derivations notebook

2. **Polynomial & Regularized Regression**
   - Implement polynomial regression
   - Visualize bias-variance tradeoff
   - Implement cross-validation from scratch
   - Build hyperparameter tuning system
   - **Deliverable:** Regression library + analysis report

**Self-Education Component:**

- Study "Elements of Statistical Learning" chapters
- Review optimization theory
- Learn regularization techniques

**Required Knowledge for This Lab:**

- Linear algebra (vectors, matrices, matrix operations)
- Calculus (derivatives, partial derivatives)
- Basic statistics (mean, variance, correlation)
- Python programming (NumPy for matrix operations)
- Understanding of optimization concepts
- Mathematical notation and derivations

---

#### Lab 2.2: Classification Algorithms ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Classification theory, probability

**Tasks:**

1. **Logistic Regression**

   - Implement from scratch with gradient descent
   - Implement Newton's method
   - Handle multi-class classification (one-vs-rest, softmax)
   - **Deliverable:** Logistic regression implementation + comparison

2. **k-NN & Naive Bayes**
   - Implement k-NN with different distance metrics
   - Optimize k-NN with data structures (KD-tree)
   - Implement Naive Bayes (Gaussian, Multinomial)
   - **Deliverable:** Classification algorithms library

**Self-Education Component:**

- Study probabilistic classification
- Review distance metrics and optimization

**Required Knowledge for This Lab:**

- Linear regression concepts (from Lab 2.1)
- Probability theory (conditional probability, Bayes' theorem)
- Understanding of classification vs regression
- Distance metrics (Euclidean, Manhattan)
- Data structures for efficient search (trees)
- Gradient descent understanding

---

### Advanced Supervised Learning

#### Lab 2.3: Support Vector Machines ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** SVM theory, convex optimization

**Tasks:**

1. **SVM Implementation**

   - Implement hard-margin SVM
   - Implement soft-margin SVM
   - Derive dual formulation
   - **Deliverable:** SVM implementation with mathematical notes

2. **Kernel Methods**
   - Implement kernel functions (RBF, polynomial, sigmoid)
   - Implement kernel trick
   - Apply to non-linear problems
   - **Deliverable:** Kernel SVM implementation + visualizations

**Self-Education Component:**

- Study convex optimization
- Review kernel methods theory
- Learn about kernel selection

**Required Knowledge for This Lab:**

- Linear algebra (dot products, norms)
- Optimization theory (convex optimization basics)
- Understanding of margins and decision boundaries
- Lagrangian multipliers (for dual formulation)
- Kernel functions concept
- Classification concepts (from Lab 2.2)

---

#### Lab 2.4: Tree-Based Methods & Ensembles ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Decision tree theory, ensemble methods

**Tasks:**

1. **Decision Trees**

   - Implement ID3, CART algorithms
   - Implement pruning (pre and post)
   - Visualize decision boundaries
   - **Deliverable:** Decision tree implementation

2. **Ensemble Methods**
   - Implement Random Forest
   - Implement Gradient Boosting (simplified)
   - Implement AdaBoost
   - Compare ensemble methods
   - **Deliverable:** Ensemble methods library + comparison study

**Self-Education Component:**

- Study boosting and bagging theory
- Review XGBoost/LightGBM papers
- Learn about feature importance

**Required Knowledge for This Lab:**

- Understanding of decision boundaries
- Information theory basics (entropy, information gain)
- Recursive algorithms
- Ensemble methods concept
- Understanding of bias-variance tradeoff
- Classification and regression concepts

---

### Unsupervised Learning & Optimization

#### Lab 2.5: Clustering & Dimensionality Reduction ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Unsupervised learning theory, linear algebra

**Tasks:**

1. **Clustering Algorithms**

   - Implement K-Means with different initializations
   - Implement DBSCAN
   - Implement Hierarchical Clustering
   - Compare clustering algorithms
   - **Deliverable:** Clustering library + evaluation metrics

2. **Dimensionality Reduction**
   - Implement PCA from scratch (SVD-based)
   - Implement t-SNE (simplified)
   - Visualize dimensionality reduction
   - **Deliverable:** Dimensionality reduction toolkit

**Self-Education Component:**

- Study linear algebra for PCA
- Review manifold learning
- Learn clustering evaluation metrics

**Required Knowledge for This Lab:**

- Linear algebra (eigenvalues, eigenvectors, SVD)
- Distance metrics (from Lab 2.2)
- Understanding of unsupervised learning
- Optimization concepts (for K-Means)
- Statistical concepts (mean, variance, covariance)
- Data preprocessing understanding

---

#### Lab 2.6: Optimization Deep Dive ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Optimization theory, numerical methods

**Tasks:**

1. **Gradient-Based Optimization**

   - Implement: SGD, Momentum, Nesterov, AdaGrad, RMSProp, Adam
   - Visualize optimization paths
   - Compare on different landscapes
   - **Deliverable:** Optimization library + visualization tool

2. **Advanced Optimization**
   - Implement learning rate scheduling
   - Implement second-order methods (Newton's, L-BFGS simplified)
   - Optimize hyperparameters using Bayesian optimization
   - **Deliverable:** Advanced optimization framework

**Self-Education Component:**

- Study optimization theory
- Review adaptive methods papers
- Learn hyperparameter tuning strategies

**Required Knowledge for This Lab:**

- Gradient descent (from Lab 2.1)
- Understanding of loss functions
- Calculus (derivatives, chain rule)
- Understanding of learning rates
- Hyperparameter concepts
- Model training concepts

---

### Advanced ML & Generative Models

#### Lab 2.7: Gaussian Mixture Models & EM ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Expectation-Maximization theory, probability

**Tasks:**

1. **EM Algorithm**

   - Derive EM algorithm mathematically
   - Implement EM for GMM
   - Handle convergence and initialization
   - **Deliverable:** EM implementation + mathematical derivation

2. **GMM Applications**
   - Apply GMM to clustering
   - Use GMM for density estimation
   - Compare with K-Means
   - **Deliverable:** GMM applications + analysis

**Self-Education Component:**

- Study EM algorithm theory
- Review mixture models
- Learn about model selection

**Required Knowledge for This Lab:**

- Probability theory (Gaussian distributions, likelihood)
- Understanding of clustering (from Lab 2.5)
- Expectation and maximization concepts
- Optimization understanding
- Statistical inference basics
- Model selection concepts

---

#### Lab 2.8: Generative Models I ‚Äî VAE & GAN ‚≠ê **MANDATORY**

**Points:** 20 points  
**Self-Study Materials:** Deep generative models papers, variational inference

**Large Project:**
**Implement Variational Autoencoder and GAN**

**Requirements:**

1. **VAE Implementation**

   - Implement VAE from scratch
   - Derive ELBO
   - Train on image dataset
   - Generate samples
   - **Deliverable:** VAE implementation + generated samples

2. **GAN Implementation**

   - Implement GAN from scratch
   - Handle training instability
   - Implement different architectures (DCGAN)
   - **Deliverable:** GAN implementation + training analysis

3. **Comparison & Analysis**
   - Compare VAE vs GAN
   - Evaluate generative quality
   - Analyze latent spaces
   - **Deliverable:** Comprehensive comparison report

**Self-Education Component:**

- Study variational inference
- Review GAN training techniques
- Learn evaluation metrics for generative models

**Required Knowledge for This Lab:**

- Deep learning basics (neural networks, backpropagation)
- Probability theory (distributions, KL divergence)
- Understanding of autoencoders
- Optimization for deep learning
- PyTorch or TensorFlow basics
- Understanding of adversarial training
- Image processing basics

---

#### Lab 2.9: Generative Models II ‚Äî Autoregressive & Flow Models üîµ **OPTIONAL**

**Points:** 18 points  
**Note:** Optional labs provide bonus points beyond the 100-point requirement  
**Self-Study Materials:** Autoregressive models, normalizing flows papers

**Advanced Project:**
**Implement Autoregressive and Flow-Based Models**

**Tasks:**

1. **Autoregressive Models**

   - Implement PixelCNN/PixelRNN
   - Train on image generation
   - Compare with VAE/GAN

2. **Normalizing Flows**
   - Implement RealNVP or Glow (simplified)
   - Understand invertible transformations
   - Generate samples

**Deliverable:** Implementation + analysis report

**Self-Education Component:**

- Study autoregressive models
- Review normalizing flows theory
- Learn about likelihood-based models

**Required Knowledge for This Lab:**

- Deep learning fundamentals
- Understanding of generative models (VAE, GAN from Lab 2.8)
- Probability theory (conditional probability, likelihood)
- Neural network architectures
- Understanding of invertible transformations
- PyTorch/TensorFlow proficiency

---

#### Lab 2.10: ML System Integration Project ‚≠ê **MANDATORY**

**Points:** 25 points  
**Self-Study Materials:** MLOps basics, model deployment

**Capstone Project:**
**Build Complete ML Pipeline System**

**Requirements:**

- Implement multiple ML algorithms from scratch
- Build automated ML pipeline:
  - Data preprocessing
  - Feature engineering
  - Model training and evaluation
  - Hyperparameter tuning
  - Model comparison
- Create ML framework with:
  - Dataset abstraction
  - Model base classes
  - Training loop
  - Evaluation metrics
- Deploy as package/library
- **Deliverable:**
  - Complete ML framework
  - Documentation and tutorials
  - Example projects
  - Final presentation (20 minutes)

**Self-Education Component:**

- Study ML framework architectures
- Review scikit-learn design
- Learn software engineering for ML

**Required Knowledge for This Lab:**

- All ML algorithms from Phase 2
- Software engineering practices (from Phase 1)
- OOP and design patterns
- Understanding of ML pipelines
- Model evaluation concepts
- Hyperparameter tuning
- System integration skills

---

## Phase 3: Deep Learning & Data Science Lab

**Focus:** Deep learning from scratch, large-scale projects, GPU optimization  
**Minimum Points Required:** 100 points to pass Phase 3

### Deep Learning Foundations

#### Lab 3.1: Neural Networks from Scratch ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** Deep learning book, backpropagation derivations

**Tasks:**

1. **Neural Network Implementation**

   - Implement fully connected network in NumPy
   - Implement forward and backward propagation
   - Implement different activation functions
   - Implement loss functions
   - **Deliverable:** NumPy-based neural network library

2. **Optimization & Training**
   - Implement optimizers (SGD, Adam)
   - Implement weight initialization (Xavier, He)
   - Implement regularization (Dropout, L2)
   - Train on real dataset
   - **Deliverable:** Complete training system + results

**Self-Education Component:**

- Study backpropagation in detail
- Review initialization strategies
- Learn about training dynamics

**Required Knowledge for This Lab:**

- Linear algebra (matrix operations)
- Calculus (derivatives, chain rule, partial derivatives)
- Understanding of optimization (from Phase 2)
- NumPy proficiency
- Understanding of activation functions
- Loss functions understanding
- Basic neural network concepts

---

#### Lab 3.2: Convolutional Neural Networks ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** CNN papers, computer vision fundamentals

**Tasks:**

1. **CNN Implementation**

   - Implement convolution operation from scratch
   - Implement pooling operations
   - Build CNN architecture
   - **Deliverable:** CNN implementation in NumPy/PyTorch

2. **CNN Training & Analysis**
   - Train on image classification dataset
   - Visualize filters and activations
   - Analyze learned features
   - Compare architectures
   - **Deliverable:** Trained models + visualization analysis

**Self-Education Component:**

- Study CNN architectures (LeNet, AlexNet, VGG, ResNet)
- Review feature visualization techniques
- Learn about transfer learning

**Required Knowledge for This Lab:**

- Neural networks from scratch (Lab 3.1)
- Understanding of convolution operation
- Image processing basics
- PyTorch or TensorFlow basics
- Understanding of pooling operations
- Backpropagation through convolution
- Transfer learning concepts

---

### Advanced Deep Learning

#### Lab 3.3: RNNs & Transformers ‚≠ê **MANDATORY**

**Points:** 12 points  
**Self-Study Materials:** RNN theory, Transformer papers

**Tasks:**

1. **RNN Implementation**

   - Implement RNN, LSTM, GRU from scratch
   - Handle vanishing gradients
   - Train on sequence data
   - **Deliverable:** RNN implementations + training results

2. **Transformer Implementation**
   - Implement attention mechanism
   - Implement multi-head attention
   - Build simplified Transformer
   - **Deliverable:** Transformer implementation + analysis

**Self-Education Component:**

- Study attention mechanisms
- Review Transformer architecture
- Learn about positional encoding

**Required Knowledge for This Lab:**

- Neural networks understanding (Lab 3.1)
- Understanding of sequences and time series
- Backpropagation through time concepts
- Understanding of vanishing gradients
- PyTorch/TensorFlow proficiency
- Understanding of attention mechanisms
- Natural language processing basics

---

#### Lab 3.4: Diffusion Models ‚≠ê **MANDATORY**

**Points:** 20 points  
**Self-Study Materials:** Diffusion model papers, score-based models

**Large Project:**
**Implement Diffusion Model from Scratch**

**Requirements:**

- Understand diffusion process mathematically
- Implement forward diffusion process
- Implement reverse diffusion (sampling)
- Implement U-Net architecture
- Train on image dataset
- Generate high-quality samples
- **Deliverable:**
  - Complete diffusion model implementation
  - Trained model
  - Generated samples
  - Mathematical derivation document
  - Training analysis report

**Self-Education Component:**

- Study DDPM and DDIM papers
- Review score-based generative models
- Learn about diffusion model variants

**Required Knowledge for This Lab:**

- Deep learning fundamentals (Lab 3.1, 3.2)
- Understanding of generative models (VAE, GAN from Lab 2.8)
- Probability theory (Gaussian processes, stochastic processes)
- Understanding of U-Net architecture
- PyTorch/TensorFlow proficiency
- Image generation concepts
- Understanding of noise schedules

---

#### Lab 3.5: Self-Supervised Learning üîµ **OPTIONAL**

**Points:** 15 points  
**Note:** Optional labs provide bonus points beyond the 100-point requirement  
**Self-Study Materials:** Self-supervised learning papers

**Advanced Project:**
**Implement Self-Supervised Learning Methods**

**Tasks:**

- Implement contrastive learning (SimCLR simplified)
- Implement pretext tasks
- Pre-train on unlabeled data
- Fine-tune on downstream tasks
- **Deliverable:** Self-supervised learning framework + results

**Self-Education Component:**

- Study contrastive learning
- Review self-supervised learning papers
- Learn about representation learning

**Required Knowledge for This Lab:**

- Deep learning fundamentals (Lab 3.1, 3.2)
- Understanding of representation learning
- Contrastive learning concepts
- Understanding of pretext tasks
- PyTorch/TensorFlow proficiency
- Transfer learning understanding
- Unsupervised learning concepts

---

### Large-Scale Projects & Optimization

#### Lab 3.6: GPU Optimization & Distributed Training ‚≠ê **MANDATORY**

**Points:** 20 points  
**Self-Study Materials:** CUDA programming, distributed training guides

**Large Project:**
**Optimize Deep Learning Training on GPU**

**Requirements:**

1. **GPU Programming**

   - Learn CUDA basics (if time permits) or use PyTorch CUDA
   - Profile GPU usage
   - Optimize memory usage
   - Implement mixed precision training
   - **Deliverable:** GPU optimization report

2. **Distributed Training**

   - Implement data parallelism
   - Implement model parallelism (if applicable)
   - Use distributed training frameworks
   - Scale training to multiple GPUs
   - **Deliverable:** Distributed training system

3. **Performance Optimization**
   - Optimize data loading (DataLoader optimization)
   - Implement gradient accumulation
   - Optimize batch processing
   - Achieve significant speedup
   - **Deliverable:**
     - Optimized training pipeline
     - Performance benchmarks
     - Optimization techniques documentation

**Self-Education Component:**

- Study GPU architecture
- Review distributed training strategies
- Learn about optimization techniques

**Required Knowledge for This Lab:**

- Deep learning training (from previous labs)
- Understanding of GPU basics
- PyTorch/TensorFlow CUDA operations
- Understanding of data parallelism
- Model training optimization
- Memory management concepts
- Performance profiling understanding

---

#### Lab 3.7: Large-Scale Computer Vision Project ‚≠ê **MANDATORY**

**Points:** 25 points  
**Self-Study Materials:** Computer vision papers, transfer learning

**Capstone Project:**
**Build Production-Ready Computer Vision System**

**Requirements:**

- Choose one of:
  - Object detection system (YOLO, Faster R-CNN)
  - Image segmentation system (U-Net, DeepLab)
  - Image generation system (GAN, Diffusion)
  - Multi-modal system (CLIP-based)
- Implement from scratch or fine-tune pre-trained models
- Handle large-scale dataset
- Optimize for inference
- Create deployment pipeline
- **Deliverable:**
  - Complete system
  - Trained models
  - Inference pipeline
  - Performance benchmarks
  - Deployment guide
  - Final presentation (25 minutes)

**Self-Education Component:**

- Study chosen domain in depth
- Review state-of-the-art methods
- Learn deployment strategies

**Required Knowledge for This Lab:**

- CNNs and computer vision (Lab 3.2)
- Transfer learning understanding
- Object detection or segmentation concepts (depending on choice)
- PyTorch/TensorFlow proficiency
- Model optimization and deployment
- Understanding of inference optimization
- Large-scale training experience

---

#### Lab 3.8: Large-Scale NLP Project ‚≠ê **MANDATORY**

**Points:** 25 points  
**Self-Study Materials:** NLP papers, transformer architectures

**Capstone Project:**
**Build Production-Ready NLP System**

**Requirements:**

- Choose one of:
  - Language model (GPT-like)
  - Text classification system
  - Named Entity Recognition
  - Question Answering system
  - Text generation system
- Fine-tune or train transformer models
- Handle large text datasets
- Optimize for inference
- Create API for deployment
- **Deliverable:**
  - Complete NLP system
  - Trained models
  - API for inference
  - Evaluation results
  - Deployment guide
  - Final presentation (25 minutes)

**Self-Education Component:**

- Study transformer architectures
- Review NLP best practices
- Learn about model compression

**Required Knowledge for This Lab:**

- Transformers and RNNs (Lab 3.3)
- Natural language processing basics
- Understanding of tokenization and embeddings
- PyTorch/TensorFlow proficiency
- Large language model concepts
- Text processing and preprocessing
- Model fine-tuning understanding

---

#### Lab 3.9: Multi-Modal AI Project üîµ **OPTIONAL**

**Points:** 18 points  
**Note:** Optional labs provide bonus points beyond the 100-point requirement  
**Self-Study Materials:** Multi-modal learning papers, CLIP

**Advanced Project:**
**Build Multi-Modal AI System**

**Tasks:**

- Implement CLIP-like model (simplified)
- Or build image captioning system
- Or build visual question answering system
- Train on multi-modal dataset
- **Deliverable:** Multi-modal system + results

**Self-Education Component:**

- Study contrastive learning for multi-modal
- Review CLIP and related papers
- Learn about cross-modal retrieval

**Required Knowledge for This Lab:**

- Computer vision (Lab 3.2, 3.7)
- NLP understanding (Lab 3.3, 3.8)
- Contrastive learning (Lab 3.5)
- Understanding of multi-modal learning
- PyTorch/TensorFlow proficiency
- Understanding of vision-language models
- Cross-modal understanding concepts

---

#### Lab 3.10: Final Capstone Project ‚≠ê **MANDATORY**

**Points:** 30 points  
**Self-Study Materials:** Research papers, state-of-the-art methods

**Ultimate Capstone:**
**Build Complete AI System ‚Äî Research-Level Project**

**Requirements:**

- Choose ambitious project combining multiple concepts:
  - Large-scale deep learning system
  - Novel architecture or approach
  - Real-world application
  - Production deployment
- Examples:
  - Build and deploy recommendation system
  - Create AI-powered application
  - Research project with novel contributions
  - Optimize and deploy large model
- Must include:
  - Literature review
  - System design
  - Implementation
  - Comprehensive evaluation
  - Deployment (if applicable)
  - Written report (15-20 pages)
  - Code repository
  - Demo/presentation (30 minutes)

**Deliverable:**

- Complete project
- Research-quality report
- Code repository
- Demo video
- Final presentation

**Self-Education Component:**

- Deep dive into chosen domain
- Study related research papers
- Learn production deployment
- Review best practices

**Required Knowledge for This Lab:**

- All Phase 3 concepts integrated
- Deep learning mastery (all previous labs)
- Research methodology understanding
- System design and architecture
- Model deployment and optimization
- GPU optimization (Lab 3.6)
- Large-scale project experience
- Research paper reading and implementation skills

---

## Lab Assessment & Grading

### Points System Overview

**Phase Passing Requirements:**

- **Phase 1:** Minimum 100 points required to pass
- **Phase 2:** Minimum 100 points required to pass
- **Phase 3:** Minimum 100 points required to pass

**Points Distribution:**

- Points are earned by completing labs and projects
- Each lab has assigned point values based on complexity and scope
- Students must accumulate minimum points to advance to next phase

### Lab Completion Requirements

**Mandatory Labs (‚≠ê):**

- Must complete enough mandatory labs to reach 100 points
- Each lab has specific deliverables
- Code quality and documentation are evaluated
- Points are awarded based on completion quality

**Optional Labs (üîµ):**

- Bonus points beyond the 100-point requirement
- Can choose based on interest
- Count toward final grade and can improve overall score

### Evaluation Criteria

1. **Code Quality** (30%)

   - Correctness
   - Efficiency
   - Clean code principles
   - Documentation

2. **Implementation Depth** (25%)

   - Completeness
   - Understanding demonstrated
   - From-scratch implementation

3. **Analysis & Reports** (20%)

   - Quality of analysis
   - Mathematical rigor
   - Visualization quality
   - Conclusions drawn

4. **Self-Education** (15%)

   - Evidence of independent learning
   - Application of learned concepts
   - Going beyond provided materials

5. **Presentation** (10%)
   - Clarity of explanation
   - Communication skills
   - Demo quality

### Points Summary by Phase

#### Phase 1: Computational & Programming Foundations

**Total Mandatory Points Available:** 127 points  
**Minimum Required:** 100 points  
**Optional Points Available:** Up to 39 points

| Lab                                   | Points               | Type         |
| ------------------------------------- | -------------------- | ------------ |
| Lab 1.1: Python Fundamentals          | 12                   | ‚≠ê Mandatory |
| Lab 1.2: System Programming           | 12                   | ‚≠ê Mandatory |
| Lab 1.3: Data Structures & Algorithms | 18                   | ‚≠ê Mandatory |
| Lab 1.4: OOP Design                   | 15                   | ‚≠ê Mandatory |
| Lab 1.5: Software Engineering         | 12                   | ‚≠ê Mandatory |
| Lab 1.6: Data Pipeline                | 20                   | ‚≠ê Mandatory |
| Lab 1.7: Database & API               | 15                   | ‚≠ê Mandatory |
| Lab 1.8: Performance Optimization     | 18                   | ‚≠ê Mandatory |
| Lab 1.9: Final Integration            | 25                   | ‚≠ê Mandatory |
| Lab 1.10: Advanced Topics             | 8 per topic (max 24) | üîµ Optional  |
| Lab 1.11: Advanced Linux              | 15                   | üîµ Optional  |

**Note:** Students need to complete at least 100 points from mandatory labs. Lab 1.9 (25 points) is highly recommended as it's the capstone project.

#### Phase 2: Machine Learning Deep Dive

**Total Mandatory Points Available:** 120 points  
**Minimum Required:** 100 points  
**Optional Points Available:** Up to 18 points

| Lab                             | Points | Type         |
| ------------------------------- | ------ | ------------ |
| Lab 2.1: Linear Models          | 12     | ‚≠ê Mandatory |
| Lab 2.2: Classification         | 12     | ‚≠ê Mandatory |
| Lab 2.3: SVM                    | 12     | ‚≠ê Mandatory |
| Lab 2.4: Trees & Ensembles      | 12     | ‚≠ê Mandatory |
| Lab 2.5: Clustering & PCA       | 12     | ‚≠ê Mandatory |
| Lab 2.6: Optimization           | 12     | ‚≠ê Mandatory |
| Lab 2.7: GMM & EM               | 12     | ‚≠ê Mandatory |
| Lab 2.8: VAE & GAN              | 20     | ‚≠ê Mandatory |
| Lab 2.9: Autoregressive & Flow  | 18     | üîµ Optional  |
| Lab 2.10: ML System Integration | 25     | ‚≠ê Mandatory |

**Note:** Students need to complete at least 100 points from mandatory labs. Lab 2.10 (25 points) is highly recommended as it's the capstone project.

#### Phase 3: Deep Learning & Data Science

**Total Mandatory Points Available:** 124 points  
**Minimum Required:** 100 points  
**Optional Points Available:** Up to 53 points

| Lab                          | Points | Type         |
| ---------------------------- | ------ | ------------ |
| Lab 3.1: Neural Networks     | 12     | ‚≠ê Mandatory |
| Lab 3.2: CNNs                | 12     | ‚≠ê Mandatory |
| Lab 3.3: RNNs & Transformers | 12     | ‚≠ê Mandatory |
| Lab 3.4: Diffusion Models    | 20     | ‚≠ê Mandatory |
| Lab 3.5: Self-Supervised     | 15     | üîµ Optional  |
| Lab 3.6: GPU Optimization    | 20     | ‚≠ê Mandatory |
| Lab 3.7: Large-Scale CV      | 25     | ‚≠ê Mandatory |
| Lab 3.8: Large-Scale NLP     | 25     | ‚≠ê Mandatory |
| Lab 3.9: Multi-Modal AI      | 18     | üîµ Optional  |
| Lab 3.10: Final Capstone     | 30     | ‚≠ê Mandatory |
| Lab 3.11: Advanced GPU Arch  | 20     | üîµ Optional  |
| Lab 3.11: Advanced GPU Arch  | 20     | üîµ Optional  |

**Note:** Students need to complete at least 100 points from mandatory labs. Lab 3.10 (30 points) is highly recommended as it's the final capstone project.

### Lab Schedule

- **Lab Sessions:** 
  - Practice Assistant-led sessions: 2-3 times per week (primary teaching and hands-on support)
  - Practice Assistant lectures: As needed (can substitute for Lecture or provide supplementary teaching)
  - Lecture check-ins: Monthly for high-level guidance and strategic oversight
- **Self-Study Time:** Required for all labs (independent work using materials provided by Practice Assistant)
- **Project Time:** Varies by project complexity
- **Office Hours:**
  - Practice Assistant: Extended regular drop-in hours for technical support, debugging, and conceptual questions
  - Lecture: On-demand consultation for complex theoretical questions and strategic guidance
- **Assessment Sessions:**
  - Practice Assistant: Regular code reviews and assessments throughout the program
  - Lecture: Final capstone project reviews (Lab 1.9, 2.10, 3.10)
- **Total Lab Hours:** ~400-500 hours over 15 months

### Resources Provided

- **Self-Study Materials:**

  - Curated reading lists (provided by Practice Assistant)
  - Paper collections (provided by Practice Assistant)
  - Tutorial notebooks (provided by Practice Assistant)
  - Video lectures (provided by Practice Assistant; Lecture provides high-level resources when available)
  - Code examples (provided by Practice Assistant)
  - Reference implementations (provided by Practice Assistant)

- **Support:**

  - **Lecture Support:**
    - Monthly check-ins and high-level strategic guidance
    - On-demand consultation for complex theoretical questions
    - Final capstone project reviews (Lab 1.9, 2.10, 3.10)
    - Final approval for phase progression decisions

  - **Practice Assistant Support (Primary Support Provider):**
    - **Teaching & Lecturing:** Regular lectures and lessons (can substitute for Lecture when needed)
    - **Lab Sessions:** Regular lab sessions (2-3 times per week) for hands-on help and teaching
    - **Office Hours:** Extended drop-in hours for debugging, technical questions, and conceptual guidance
    - **Code Review:** Comprehensive code review sessions (individual and group)
    - **Assessment:** All lab assessments and phase progression evaluations
    - **Real-Time Support:** Continuous support via chat/discussion platforms
    - **Workshops:** Comprehensive workshops on tools, frameworks, and best practices
    - **Progress Monitoring:** Detailed tracking and feedback for all students
    - **Curriculum Development:** Creates and maintains lab materials and resources
    - **Technical Mentoring:** One-on-one tutoring and career guidance

  - **Peer Collaboration:**
    - Encouraged for learning and knowledge sharing
    - Group code review sessions facilitated by Practice Assistant
    - Study groups and peer problem-solving organized by Practice Assistant

---

## Lab Progression Path

### Phase 1 ‚Üí Phase 2

**Prerequisites:**

- Accumulate minimum 100 points from Phase 1 labs
- Complete at least Lab 1.9 (Final Integration Project - 25 points) or equivalent large project
- Demonstrate proficiency in Python and algorithms
- Pass Phase 1 lab assessment (code review + technical interview)

### Phase 2 ‚Üí Phase 3

**Prerequisites:**

- Accumulate minimum 100 points from Phase 2 labs
- Complete at least Lab 2.10 (ML System Integration - 25 points) or equivalent large project
- Demonstrate ML algorithm understanding
- Pass Phase 2 lab assessment (project review + quiz)

### Phase 3 Completion

**Requirements:**

- Accumulate minimum 100 points from Phase 3 labs
- Complete Lab 3.10 (Final Capstone Project - 30 points)
- Demonstrate deep learning mastery
- Pass Phase 3 lab assessment (capstone review + technical interview)

---

_This lab plan is designed to provide hands-on mastery through deep implementation, large projects, and self-directed learning, preparing students for real-world AI/ML engineering challenges._
